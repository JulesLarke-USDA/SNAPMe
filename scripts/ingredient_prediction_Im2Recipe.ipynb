{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9508ded4",
   "metadata": {},
   "source": [
    "### Title: ingredient_prediction_Im2Recipe\n",
    "\n",
    "__Date:__ 5/8/23\n",
    "\n",
    "__Author:__ Jules Larke\n",
    " \n",
    "__Purpose__  \n",
    "Generate F1 scores for per meal image based on text descriptions predicted with the Im2Recipe algorithm\n",
    "\n",
    "__Required Input Files__\n",
    "\n",
    "  - **snapme_result_clean.json** - Ingredient prediction output using im2recipe model with SNAPMe dataset (before photos) from Donghee Lee\n",
    "  - **snapme_inv_cook_f1_score_050823.csv** - Output from ingredient_prediction_Inverse_Cooking.ipynb. Used to .loc the image filenames so the same data is being used. Also, links metadata; food_count, Occ_Name and single_multi\n",
    "\n",
    "__Output__\n",
    "- **snapme_im2r_f1_score_050823.csv** Will be the input for data visualization and statistics in f1_score_testing_visualization.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b9fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "wn = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ed1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "im2r = pd.read_json(\"im2recipe/snapme_clean/snapme_result_clean.json\")\n",
    "fb_inv_res = pd.read_csv('snapme_inv_cook_f1_score_050823.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0852541",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fb_inv_res = fb_inv_res[['Food_Description', 'filename', 'food_count', 'Occ_Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ba398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2r = im2r.transpose().reset_index().rename(columns={'index': 'filename'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfacb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2r.filename = im2r.filename + '.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1866041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im2r = im2r.loc[im2r.filename.isin(fb_inv_res.filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4723b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2r_2 = pd.merge(im2r, fb_inv_res, on='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff602dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im2r_2 = im2r_2[['filename', 'Food_Description', 'top1', 'food_count', 'Occ_Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70742dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated list of stopwords based on tokens from both FNDDS and R1M that did not provide any information that could be used to identify a specific food\n",
    "stopwords = ['ns',\n",
    " 'nfs',\n",
    " '',\n",
    " 'water',\n",
    " 'dry',\n",
    " 'black',\n",
    " 'brown',\n",
    " 'bayo',\n",
    " 'cut',\n",
    " 'cooked',\n",
    " 'cooking',\n",
    " 'as',\n",
    " 'to',\n",
    " 'of',\n",
    " 'flavor',\n",
    " 'fat',\n",
    " 'eaten',\n",
    " 'made',\n",
    " 'with',\n",
    " 'raw',\n",
    " 'brewed',\n",
    " 'fried',\n",
    " 'eaten',\n",
    " 'toasted',\n",
    " 'boiled',\n",
    " 'from',\n",
    " 'fresh',\n",
    " 'type',\n",
    " 'coated',\n",
    " 'baked',\n",
    " 'or',\n",
    " 'broiled',\n",
    " 'part',\n",
    " 'and',\n",
    " 'method',\n",
    " 'skin',\n",
    " 'not',\n",
    " 'stewed',\n",
    " 'canned',\n",
    " 'table',\n",
    " 'reduced',\n",
    " 'fat',\n",
    " 'added',\n",
    " 'in',\n",
    " 'hot',\n",
    " 'granulated',\n",
    " 'ground',\n",
    " 'Mexican',\n",
    " 'blend',\n",
    " 'flavored',\n",
    " 'home',\n",
    " 'recipe',\n",
    " 'purchased',\n",
    " 'c',\n",
    " 'at',\n",
    " 'a',\n",
    " 'bakery',\n",
    " 'replacement',\n",
    " 'free',\n",
    " 'powder',\n",
    " '0',\n",
    " '1',\n",
    " '2',\n",
    " '20',\n",
    " '99',\n",
    " '100',\n",
    " 'stuffed',\n",
    " 'low',\n",
    " 'puerto',\n",
    " 'nutritional',\n",
    " 'trail',\n",
    " 'valley',\n",
    " 'shelf',\n",
    " 'brussels',\n",
    " 'hash',\n",
    " 'd',\n",
    " 'purpose',\n",
    " 'weed',\n",
    " 'sauce',\n",
    " 'lactose',\n",
    " 'spread',\n",
    " 'tap',\n",
    " 'mini',\n",
    " 'morsel',\n",
    " 'based',\n",
    " 'citrus',\n",
    " 'boiling',\n",
    " 'capn',\n",
    " 'dip',\n",
    " 'white',\n",
    " 'ripe',\n",
    " 'pot',\n",
    " 'indian',\n",
    " 'chinese',\n",
    " 'wild',\n",
    " 'carbonated',\n",
    " 'sun',\n",
    " 'cane',\n",
    " 'higher',\n",
    " 'french',\n",
    " 'loaf',\n",
    " 'mix',\n",
    " 'calorie',\n",
    " 'congee',\n",
    " 'le',\n",
    " 'american',\n",
    " 'wing',\n",
    " 'grilled',\n",
    " 'tartar',\n",
    " 'maple',\n",
    " 'wedding',\n",
    " 'kellogg',\n",
    " 'quick',\n",
    " 'mixed',\n",
    " 'pickled',\n",
    " 'devil',\n",
    " 'refried',\n",
    " 'breast',\n",
    " 'decaffeinated',\n",
    " 'mashed',\n",
    " 'puffed',\n",
    " 'substitute',\n",
    " 'solid',\n",
    " 'place',\n",
    " 'leavening',\n",
    " 'peel',\n",
    " 'coating',\n",
    " 'sunflower',\n",
    " 'filled',\n",
    " 'mein',\n",
    " 'caesar',\n",
    " 'topping',\n",
    " 'on',\n",
    " 'pilaf',\n",
    " 'mostly',\n",
    " 'cured',\n",
    " 'thigh',\n",
    " 'lightly',\n",
    " 'round',\n",
    " 'hydrogenated',\n",
    " 'dessert',\n",
    " 'melted',\n",
    " 'jack',\n",
    " 'andor',\n",
    " 'carton',\n",
    " 'monterey',\n",
    " 'cracked',\n",
    " 'active',\n",
    " 'tender',\n",
    " 'classic',\n",
    " 'plain',\n",
    " 'filling',\n",
    " 'k',\n",
    " 'new',\n",
    " 'colby',\n",
    " 'fry',\n",
    " 'containing',\n",
    " 'used',\n",
    " 'barbecue',\n",
    " 'light',\n",
    " 'rican',\n",
    " 'calcium',\n",
    " 'floured',\n",
    " 'fast',\n",
    " 'crispbread',\n",
    " 'drink',\n",
    " 'lump',\n",
    " 'scrambled',\n",
    " 'source',\n",
    " 'dark',\n",
    " 'grecian',\n",
    " 'uncooked',\n",
    " 'sauteed',\n",
    " 'air',\n",
    " 'snack',\n",
    " 'loop',\n",
    " 'english',\n",
    " 'string',\n",
    " 'organic',\n",
    " 'path',\n",
    " 'winter',\n",
    " 'semi',\n",
    " 'greek',\n",
    " 'crude',\n",
    " 'woven',\n",
    " 'dipped',\n",
    " 'vienna',\n",
    " 'edamame',\n",
    " 'leg',\n",
    " 'homemade',\n",
    " 'cone',\n",
    " 'unsweetened',\n",
    " 'summer',\n",
    " 'sugared',\n",
    " 'nut',\n",
    " 'palm',\n",
    " 'feta',\n",
    " 'eat',\n",
    " 'spanish',\n",
    " 'heavy',\n",
    " 'generic',\n",
    " 'herbal',\n",
    " 'nonfat',\n",
    " 'liquid',\n",
    " 'chop',\n",
    " 'squeezed',\n",
    " 'ruffled',\n",
    " 'braised',\n",
    " 'griddle',\n",
    " 'fryer',\n",
    " 'hard',\n",
    " 'unprepared',\n",
    " 'loin',\n",
    " 'great',\n",
    " 'frosted',\n",
    " 'enriched',\n",
    " 'sprouted',\n",
    " 'evaporated',\n",
    " 'sweetener',\n",
    " 'plus',\n",
    " 'bouillon',\n",
    " 'pho',\n",
    " '80',\n",
    " 'kidney',\n",
    " 'instant',\n",
    " 'concentrate',\n",
    " 'average',\n",
    " 'grated',\n",
    " 'flake',\n",
    " 'includes',\n",
    " 'distilled',\n",
    " 'cafe',\n",
    " 'sulfate',\n",
    " 'prepackaged',\n",
    " 'ascorbic',\n",
    " 'armenian',\n",
    " 'boston',\n",
    " 'alcohol',\n",
    " 'medium',\n",
    " 'paste',\n",
    " 'dairy',\n",
    " 'slice',\n",
    " 'packaged',\n",
    " 'jam',\n",
    " 'iced',\n",
    " 'acid',\n",
    " 'pre',\n",
    " 'other',\n",
    " 'whipped',\n",
    " 'creamer',\n",
    " 'ea',\n",
    " 'edam',\n",
    " 'serve',\n",
    " 'pattie',\n",
    " 'gallo',\n",
    " 'confectionery',\n",
    " 'it',\n",
    " 'general',\n",
    " 'real',\n",
    " 'tenderloin',\n",
    " 'tub',\n",
    " 'bit',\n",
    " 'restaurant',\n",
    " 'smoked',\n",
    " 'reconstituted',\n",
    " 'kettle',\n",
    " 'creamed',\n",
    " 'unsalted',\n",
    " 'mocha',\n",
    " 'two',\n",
    " 'scalloped',\n",
    " 'canola',\n",
    " 'household',\n",
    " 'whey',\n",
    " 'bunch',\n",
    " 'chai',\n",
    " 'unroasted',\n",
    " 'kernel',\n",
    " 'one',\n",
    " 'dried',\n",
    " 'japanese',\n",
    " 'joe',\n",
    " 'gluten',\n",
    " 'meatless',\n",
    " 'breaded',\n",
    " 'non',\n",
    " 'pressurized',\n",
    " 'queso',\n",
    " 'submarine',\n",
    " 'rolo',\n",
    " 'thin',\n",
    " 'froot',\n",
    " 'sour',\n",
    " 'square',\n",
    " 'for',\n",
    " 'agent',\n",
    " 'luncheon',\n",
    " 'fresco',\n",
    " 'mackerel',\n",
    " 'grain',\n",
    " 'microwave',\n",
    " 'deglet',\n",
    " 'leaf',\n",
    " 'thins',\n",
    " 'bottled',\n",
    " 'color',\n",
    " 'restructured',\n",
    " 'roasted',\n",
    " 'tart',\n",
    " 'patty',\n",
    " 'dumpling',\n",
    " 'including',\n",
    " 'drained',\n",
    " 'stable',\n",
    " 'pico',\n",
    " 'sweet',\n",
    " 'fluid',\n",
    " 'blend',\n",
    " 'flavor',\n",
    " 'regular',\n",
    " 'protein',\n",
    " 'mature',\n",
    " 'sodium',\n",
    " 'preserve',\n",
    " 'hawaiian',\n",
    " 'condiment',\n",
    " 'cultured',\n",
    " 'spray',\n",
    " 'crunch',\n",
    " 'baker',\n",
    " 'sloppy',\n",
    " 'toast',\n",
    " 'usda',\n",
    " 'mexican',\n",
    " 'dressing',\n",
    " 'frozen',\n",
    " 'thai',\n",
    " 'without',\n",
    " 'lean',\n",
    " 'unbuttered',\n",
    " 'calico',\n",
    " 'crumb',\n",
    " 'style',\n",
    " 'only',\n",
    " 'food',\n",
    " 'year',\n",
    " 'rotisserie',\n",
    " 'animal',\n",
    " 'whole',\n",
    " 'strip',\n",
    " 'brick',\n",
    " 'popped',\n",
    " 'puff',\n",
    " 'complete',\n",
    " 'leafy',\n",
    " 'form',\n",
    " 'con',\n",
    " 'deep',\n",
    " 'excluding',\n",
    " 'sulfured',\n",
    " 'casserole',\n",
    " 'spartan',\n",
    " 'steamed',\n",
    " 'shell',\n",
    " 'beverage',\n",
    " 'fruit',\n",
    " 'vegetarian',\n",
    " 'boneless',\n",
    " 'lite',\n",
    " 'breakfast',\n",
    " 'chard',\n",
    " 'heat',\n",
    " 'kashi',\n",
    " 'composite',\n",
    " 'germ',\n",
    " 'double',\n",
    " 'quaker',\n",
    " 'jr',\n",
    " 'young',\n",
    " 'goat',\n",
    " 'reeses',\n",
    " 'alfredo',\n",
    " 'than',\n",
    " 'semisweet',\n",
    " 'about',\n",
    " 'unenriched',\n",
    " 'marinade',\n",
    " 'baking',\n",
    " 'chow',\n",
    " 'ready',\n",
    " 'poultry',\n",
    " 'cheez',\n",
    " 'soft',\n",
    " 'mung',\n",
    " 'high',\n",
    " 'multigrain',\n",
    " 'farmer',\n",
    " 'diet',\n",
    " 'lowfat',\n",
    " 'italian',\n",
    " 'major',\n",
    " 'no',\n",
    " 'verde',\n",
    " 'bay',\n",
    " 'yellow',\n",
    " 'commercially',\n",
    " 'brie',\n",
    " 'mill',\n",
    " 'degermed',\n",
    " 'balsamic',\n",
    " 'root',\n",
    " 'red',\n",
    " 'nature',\n",
    " 'covered',\n",
    " 'poached',\n",
    " 'raised',\n",
    " 'california',\n",
    " 'prepared',\n",
    " 'freshly',\n",
    " 'blue',\n",
    " 'post',\n",
    " 'cotija',\n",
    " 'golean',\n",
    " 'glazed',\n",
    " 'processed',\n",
    " 'microwaving',\n",
    " 'salted',\n",
    " 'dripping',\n",
    " 'aluminum',\n",
    " 'powdered',\n",
    " 'shoulder',\n",
    " 'broiler',\n",
    " 'all',\n",
    " 'creamy',\n",
    " 'lower',\n",
    " '011213162966',\n",
    " 'mush',\n",
    " 'like',\n",
    " 'carne',\n",
    " 'cappuccino',\n",
    " 'half',\n",
    " 'spice',\n",
    " 'noor',\n",
    " 'crust',\n",
    " 'de',\n",
    " 'canadian',\n",
    " 'base',\n",
    " 'thick',\n",
    " 'pad',\n",
    " 'cutlet',\n",
    " 'bar',\n",
    " 'condensed',\n",
    " 'snap',\n",
    " 'caffeine',\n",
    " 'hoisin',\n",
    " 'sweetened',\n",
    " 'upc',\n",
    " 'nugget',\n",
    " 'cup',\n",
    " 'king',\n",
    " 'sponge',\n",
    " 'sprinkle',\n",
    " 'commodity',\n",
    " 'small',\n",
    " 'curd',\n",
    " 'bran',\n",
    " 'link',\n",
    " 'combination',\n",
    " 'england',\n",
    " 'deli',\n",
    " 'acting',\n",
    " 'dog',\n",
    " 'skinless',\n",
    " 'special',\n",
    " 'smooth',\n",
    " 'hoagie',\n",
    " 'skim',\n",
    " 'vitamin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7929fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation[0:11] + string.punctuation[13:] # remove '-' from the list of punctuation. This is needed for the tokenizer in the following cell\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in punct])\n",
    "    tokens = re.split('[-\\W+]', text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return set(text)\n",
    "\n",
    "im2r_2['clean_description'] = im2r_2['Food_Description'].apply(lambda x: clean_text(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b0295c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im2r_2['top1'] = [','.join(map(str, l)) for l in im2r_2['top1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d91d0",
   "metadata": {},
   "source": [
    "## Now clean text descriptions for Im2R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ac63da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in punct])\n",
    "    tokens = re.split('[-\\W+]', text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return set(text)\n",
    "\n",
    "im2r_2['clean_im2r'] = im2r_2['top1'].apply(lambda x: clean_text(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6b0722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_detection(a,b):\n",
    "    tp = sum(any(m == L for m in a) for L in b)\n",
    "    fn = len(a) - tp\n",
    "    fp = len(b) - sum(any(m == L for m in b) for L in a)\n",
    "    try:\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2 * precision * recall)/(precision + recall)\n",
    "        return(f1)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce4170b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [string_detection(x, y) for x, y in zip(im2r_2['clean_description'], im2r_2['clean_im2r'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba0eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2r_2['F1_score'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10a83412",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2r_2.to_csv('../output/snapme_im2r_f1_score_050823.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
